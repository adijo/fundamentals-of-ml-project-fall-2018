ConvNet(
  (layer1): Sequential(
    (0): Dropout(p=0.2)
    (1): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1))
    (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): ReLU()
  )
  (layer2): Sequential(
    (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1))
    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (layer3): Sequential(
    (0): Dropout(p=0.5)
    (1): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2))
    (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): ReLU()
  )
  (layer4): Sequential(
    (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1))
    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (layer5): Sequential(
    (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1))
    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (layer6): Sequential(
    (0): Dropout(p=0.5)
    (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2))
    (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=3072, out_features=10, bias=True)
)
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
Learning rate: 0.001
Epoch [1/10], Step [50/450], Loss: 1.7139, Accuracy:0.27
Epoch [1/10], Step [100/450], Loss: 1.7585, Accuracy:0.32
Epoch [1/10], Step [150/450], Loss: 1.4927, Accuracy:0.35
Epoch [1/10], Step [200/450], Loss: 1.3272, Accuracy:0.37
Epoch [1/10], Step [250/450], Loss: 1.4695, Accuracy:0.39
Epoch [1/10], Step [300/450], Loss: 1.6065, Accuracy:0.40
Epoch [1/10], Step [350/450], Loss: 1.4318, Accuracy:0.41
Epoch [1/10], Step [400/450], Loss: 1.5692, Accuracy:0.42
Epoch [1/10], Step [450/450], Loss: 1.2435, Accuracy:0.43
